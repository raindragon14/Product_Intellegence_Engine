# ğŸš€ Product Intelligence Engine - Quick Start Guide

## ğŸ“‹ Setup Instructions

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Configure Environment
```bash
# Copy the example env file
cp .env.example .env

# Edit .env and add your Gemini API key
# Get your key from: https://ai.google.dev/
```

### 3. Update Configuration (Optional)
Edit `config/config.py` to customize:
- App ID (default: `com.unnes.myunnes`)
- Max reviews to scrape
- LLM model settings

## ğŸƒ Running the Pipeline

### Option 1: Full Pipeline (Recommended)
Run everything from scraping to analysis:
```bash
python main.py
```

### Option 2: With Custom Parameters
```bash
python main.py --app-id com.example.app --max-reviews 500
```

### Option 3: Step by Step

**Step 1: Scrape Reviews**
```bash
python main.py --scrape-only
```

**Step 2: Process with LLM**
```bash
python main.py --process-only
```

**Step 3: Generate Visualizations**
```bash
python main.py --visualize-only
```

### Option 4: Individual Scripts

**Scraping only:**
```bash
python scripts/scraper.py
```

**Processing only:**
```bash
python scripts/process_llm.py
```

**Visualization only:**
```bash
python scripts/visualize.py
```

## ğŸ“Š Using Jupyter Notebook

For data exploration and visualization:
```bash
jupyter notebook notebooks/data_exploration.ipynb
```

## ğŸ“ Output Files

- **Raw Data**: `data/raw/reviews_*.csv`
- **Processed Data**: `data/processed/processed_reviews_*.csv`
- **Dashboard Exports**: `dashboard/exports/`
  - `looker_studio_data.csv` - Main file for Looker Studio
  - `*.png` - Generated charts
  - `dashboard_summary.json` - Summary statistics
- **Logs**: `pipeline.log`

## ğŸ¯ Next Steps

1. **Check Generated Charts**: Open `dashboard/exports/` to see visualizations
2. **Import to Looker Studio**: Upload `looker_studio_data.csv` to create interactive dashboards
3. **Follow Dashboard Guide**: Read `dashboard/looker_studio_guide.md` for detailed setup
4. **Analyze Trends**: Use the Jupyter notebook for deeper insights
5. **Share with Team**: Export insights and visualizations

## âš™ï¸ Configuration Options

### In `config/config.py`:

```python
# Scraper settings
SCRAPER_CONFIG = {
    "app_id": "com.unnes.myunnes",
    "max_reviews": 1000,
    "language": "id",
    "country": "id",
}

# LLM settings
LLM_CONFIG = {
    "model": "gemini-1.5-flash",
    "temperature": 0.3,
    "batch_size": 10,
}
```

## ğŸ†˜ Troubleshooting

**Issue**: API key error
- **Solution**: Make sure `.env` file exists with valid `GEMINI_API_KEY`

**Issue**: No data scraped
- **Solution**: Check app ID is correct and app has reviews

**Issue**: Rate limiting
- **Solution**: Reduce `batch_size` in config or increase delay

## ğŸ“š Project Structure

```
Product_Intellegence_Engine/
â”œâ”€â”€ config/              # Configuration files
â”‚   â””â”€â”€ config.py       # Central configuration
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/            # Scraped reviews
â”‚   â””â”€â”€ processed/      # Classified reviews
â”œâ”€â”€ scripts/            # Core modules
â”‚   â”œâ”€â”€ scraper.py      # Web scraper
â”‚   â”œâ”€â”€ process_llm.py  # LLM processor
â”‚   â””â”€â”€ visualize.py    # Chart generator
â”œâ”€â”€ utils/              # Helper functions
â”‚   â”œâ”€â”€ data_handler.py # Data operations
â”‚   â””â”€â”€ logger.py       # Logging utilities
â”œâ”€â”€ notebooks/          # Jupyter notebooks
â”‚   â””â”€â”€ data_exploration.ipynb
â”œâ”€â”€ dashboard/          # Dashboard files
â”‚   â”œâ”€â”€ exports/        # Generated charts & data
â”‚   â”œâ”€â”€ README.md       # Dashboard guide
â”‚   â”œâ”€â”€ looker_studio_guide.md
â”‚   â””â”€â”€ sample_dashboard_config.json
â”œâ”€â”€ main.py             # Main pipeline
â”œâ”€â”€ requirements.txt    # Dependencies
â”œâ”€â”€ .env.example        # Environment template
â””â”€â”€ QUICKSTART.md       # This file
```

## ğŸ¤ Contributing

Feel free to submit issues or pull requests!

## ğŸ“„ License

MIT License - see LICENSE file for details
